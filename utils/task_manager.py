# import sched
from apscheduler.schedulers.background import BackgroundScheduler
import threading
import time
import os
import glob
import ffmpeg
import psutil
import subprocess
from datetime import datetime, timedelta
# from multiprocessing import Process, Manager
import multiprocessing
import logging
from moviepy.editor import VideoFileClip
from send2trash import send2trash
from concurrent.futures import ThreadPoolExecutor
from config.config import settings
import zipfile
import asyncio
import schedule
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.executors.asyncio import AsyncIOExecutor
from utils.lotto_schedule import async_buy_lotto
import re

tasks = []

# sched ê¸°ë³¸ ìŠ¤ì¼€ì¤„ëŸ¬, ë¸”ë¡œí‚¹
# scheduler = sched.scheduler(time.time, time.sleep)

# ìŠ¤ì¼€ì¤„ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ë…¼ë¸”ë¡œí‚¹)
scheduler = BackgroundScheduler()
work_directory = settings['WORK_DIRECTORY']
TEMP_IMAGE_DIR = settings['TEMP_IMAGE_DIR']
TRIP_IMAGE_DIR = settings['TRIP_IMAGE_DIR']
DIRECTORIES_TO_COMPRESS = [TEMP_IMAGE_DIR, TRIP_IMAGE_DIR]
OUTPUT_ZIP_FILE = "compressed_all_files.zip"

'''
    # 1. multiprocessingëŠ” ë©”ëª¨ë¦¬ë¥¼ ê³µìœ í•˜ì§€ ì•ŠëŠ”ë‹¤ -> classì˜ í•„ë“œë¥¼ ê³µìœ í•˜ì§€ ì•ŠìŒ
    # process = multiprocessing.Process(target=self.generate_thumbnail)
    # process.start() 

    # 2. ìŠ¤ë ˆë“œë¥¼ ë¬´í•œíˆ ìƒì„±í•˜ëŠ” ì˜¤ë¥˜
    #thread = threading.Thread(target=self.generate_thumbnail) 
    #thread.start()

    # 3. ìì‹ í”„ë¡œì„¸ìŠ¤ê°€ ë¬´í•œíˆ ì¦ì‹í•œë‹¤..
    #self.executor.submit(self.generate_thumbnail) 
'''

class Task:
    def __init__(self, pid, file_pattern, work_directory, url):
        self.pid = pid
        self.file_pattern = file_pattern
        self.work_directory = work_directory
        self.last_modified_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        self.last_checked_time = None
        self.file_name = None
        self.thumbnail_path = None
        self.thumbnail_update_time = None
        self.creation_time = datetime.now()
        self.initial_thumbnail_created = False
        self.thumbnail_duration = 0
        self.url = url
        #self.executor = ThreadPoolExecutor(max_workers=10) # ìŠ¤ë ˆë“œ í’€

    def update_last_modified(self):
        latest_file = self.get_latest_file()
        # print(f"Latest file: {latest_file}")
        if latest_file is not None:
            self.file_name = os.path.basename(latest_file)
            if not self.initial_thumbnail_created:
                self.creation_time = datetime.fromtimestamp(os.path.getctime(latest_file))
            if latest_file is not None:
                last_modified_time = datetime.fromtimestamp(os.path.getmtime(latest_file))
                if self.last_checked_time is None or last_modified_time != self.last_checked_time:
                    self.last_modified_time = last_modified_time.strftime('%Y-%m-%d %H:%M:%S')
                    self.last_checked_time = last_modified_time
                    # print(f"######### Updated ######### : {self.file_name} - - {self.thumbnail_update_time} - - {self.last_modified_time}")
                    self.set_param_generate_thumbnail()

    def set_param_generate_thumbnail(self):
        # ì²˜ìŒë¶€í„° ffmpegë¥¼ import í–ˆìœ¼ë©´ multiprocessingì„ ì‚¬ìš©í•  ì´ìœ ê°€ ìˆì—ˆì„ê¹Œ?
        params = {
            'pid': self.pid,
            'file_name': self.file_name,
            'work_directory': self.work_directory,
            'initial_thumbnail_created': self.initial_thumbnail_created,
            'thumbnail_path': self.thumbnail_path,
            'thumbnail_update_time': self.thumbnail_update_time,
            'last_modified_time': self.last_modified_time,
            'creation_time': self.creation_time,
        }

        # multiprocessing.Manager > ê³µìœ  dict
        manager = Manager()
        return_dict = manager.dict()
        process = Process(target=self.generate_thumbnail, args=(params, return_dict))
        process.start()
        process.join()

        # í”„ë¡œì„¸ìŠ¤ê°€ ì™„ë£Œëœ í›„ ê³µìœ ëœ dictì—ì„œ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜´
        self.thumbnail_path = return_dict.get('thumbnail_path')
        self.thumbnail_update_time = return_dict.get('thumbnail_update_time')
        self.initial_thumbnail_created = return_dict.get('initial_thumbnail_created')

    def get_latest_file(self):
        search_pattern = os.path.join(self.work_directory, self.file_pattern)
        files = glob.glob(search_pattern)

        if not files:
            return None

        latest_file = max(files, key=os.path.getctime) # ìˆ˜ì •ì‹œê°„ ë”œë ˆì´ ì´ìŠˆ
        # latest_file = max(files, key=os.path.getmtime)
        return latest_file

    def generate_thumbnail(self, params, return_dict):
        pid = params.get("pid")
        file_name = params.get("file_name")
        work_directory = params.get("work_directory")
        creation_time = params.get("creation_time")
        last_modified_time = params.get("last_modified_time")
        initial_thumbnail_created = params.get("initial_thumbnail_created")
        thumbnail_update_time = params.get("thumbnail_update_time")
        thumbnail_path = os.path.join(work_directory, file_name.replace('.ts', '_thumb.webp'))
        target_file = os.path.join(work_directory, file_name)


        if file_name and creation_time and is_process_running(pid):
            if not initial_thumbnail_created:
                # ìµœì´ˆ ì¸ë„¤ì¼ ìƒì„± (íŒŒì¼ ì‹œì‘ 1ì´ˆ í›„)
                (
                    ffmpeg.input(target_file, ss=1)
                    .output(thumbnail_path, vframes=1, q=85, pix_fmt='yuvj420p', loglevel="error", update=1)
                    .run(overwrite_output=True, capture_stdout=True, capture_stderr=True)
                )
                if os.path.exists(thumbnail_path):
                    initial_thumbnail_created = True
                    thumbnail_update_time = datetime.now().isoformat()
                else:
                    print("Failed to create initial thumbnail.")

            elif thumbnail_update_time:
                current_time = datetime.now()
                last_update_time = datetime.fromisoformat(thumbnail_update_time)

                modification_time = datetime.strptime(last_modified_time, '%Y-%m-%d %H:%M:%S')
                duration = modification_time - creation_time
                thumb_duration = duration.total_seconds()
                thumb_time_difference = (current_time - last_update_time).total_seconds()

                video_duration = get_video_duration(target_file)
                if thumb_duration > video_duration:
                    thumb_duration = video_duration - 5

                if thumb_time_difference >= 30:
                    try:
                        (
                            ffmpeg.input(target_file, ss=int(thumb_duration))
                            .output(thumbnail_path, vframes=1, q=85, pix_fmt='yuvj420p', loglevel="error", update=1) # s='640x360'
                            .run(overwrite_output=True, capture_stdout=True, capture_stderr=True)
                        )
                    except ffmpeg.Error as e:
                        # print('stdout:', e.stdout.decode('utf8'))
                        print('stderr:', e.stderr.decode('utf8'))

                    if os.path.exists(thumbnail_path):
                        thumbnail_update_time = datetime.now().isoformat()
                        # print(f"Created Thumbnail at {file_name} {thumb_duration} second mark.")
                    else:
                        print(f"Failed to create thumbnail at {thumb_duration} second mark.")



            return_dict['thumbnail_path'] = thumbnail_path
            return_dict['initial_thumbnail_created'] = initial_thumbnail_created
            return_dict['thumbnail_update_time'] = thumbnail_update_time

    @staticmethod
    def terminate(pid):
        try:
            subprocess.run(['taskkill', '/PID', str(pid), '/F', '/T'], check=True)
            print(f"Process {pid} and its children have been successfully terminated.")
        except subprocess.CalledProcessError as e:
            print(f"Failed to terminate process {pid} and its children: {e}")
        except Exception as e:
            print(f"An error occurred: {e}")

def is_process_running(pid):
    """ Check if a process with a given pid is running """
    if pid is None:
        print(f"## Process PID {pid} is None ## : ")
        return False
    try:
        # psutil will throw NoSuchProcess exception if pid does not exist
        process = psutil.Process(pid)
        return process.is_running() and process.status() != psutil.STATUS_ZOMBIE
    except psutil.NoSuchProcess:
        # print("##### psutil Error ##### : ", pid)
        return False
    except Exception as e:
        print(f"##### Unexpected error ##### : {str(e)}")
        return False

# í˜„ì¬ ë‚ ì§œë¥¼ YYMMDD í˜•ì‹ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°
def current_date():
    return datetime.now().strftime('%y%m%d')


image_extensions = ('.png', '.jpg', '.jpeg', '.gif', '.webp')

# ì‘ì—…ì´ ëë‚œ task ëª©ë¡ ì œê±°
def cleanup_tasks():
    global tasks
    directory = work_directory
    if not tasks:
        return

    current_time = datetime.now()
    threshold_time = timedelta(minutes=15)  # 15ë¶„
    format_str = '%Y-%m-%d %H:%M:%S'
    new_tasks = []

    for task in tasks:
        task_time = datetime.strptime(task.last_modified_time, format_str)
        time_difference = current_time - task_time

        if time_difference < threshold_time:
            if not is_process_running(task.pid):
#                 new_tasks.append(task)
#             else:
#                 print(f"Process with pid {task.pid} is not running. Task {task.file_name} will be terminated.")
                terminate_task(task.pid)
        # 15ë¶„ ì´ˆê³¼í•˜ë©´ ì œê±°
        else :
            print(f"######### Task ############ : {task.file_name} - - time_difference : {time_difference}")
            terminate_task(task.pid)

    # ë§¤ ì •ê°ë§ˆë‹¤ ì‹¤í–‰
    if current_time.minute == 0:
        threshold_time = timedelta(minutes=30)  # 30ë¶„
        for filename in os.listdir(directory):
            if filename.lower().endswith(image_extensions):
                file_path = os.path.join(directory, filename)
                creation_time = datetime.fromtimestamp(os.path.getmtime(file_path))
                time_difference = current_time - creation_time
                if time_difference > threshold_time:
                    normalized_path = os.path.normpath(file_path)
                    send2trash(normalized_path) # íœ´ì§€í†µ
                    # print(f"Moved to trash: {file_name}")

#     tasks[:] = new_tasks
    print(f"Updated tasks array: {[task.file_name for task in tasks]}")

    '''
    íŒŒì¼ì˜ ë§ˆì§€ë§‰ ìˆ˜ì •ì‹œê°„ì´ 10ë¶„ì´ ë„˜ìœ¼ë©´ ì²´í¬í•´ì•¼í•œë‹¤
    '''
    # delete_short_videos(work_directory, 60)

# ì‘ì—… ìƒíƒœë¥¼ ì£¼ê¸°ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ëŠ” ìŠ¤ë ˆë“œ
def update_task_status():
    for task in tasks:
        task.update_last_modified()

def terminate_task(pid):
    for task in tasks:
        if task.pid == pid:
            print(f"##### Terminate Task ###### : {task.file_name} ")
            if is_process_running(pid):
                Task.terminate(pid)
            # ffmpeg_handle.kill_task í˜¸ì¶œí•œ ê²½ìš°
            try:
                tasks.remove(task)
                # print(f"Task [ {task.file_name} ] removed from tasks array.")
            except ValueError:
                print(f"Task [ {task.file_name} ] not found in tasks array.")
            break



video_extensions = ('.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv', 'ts')

# VideoFileClip í´ë˜ìŠ¤ë¡œ íŒŒì¼ì„ ì§ì ‘ ì—°ë‹¤ (ë©”ëª¨ë¦¬ ë§ì´ ì‚¬ìš©í•œë‹¤)
def get_video_length(file_path):
    try:
        clip = VideoFileClip(file_path)
        duration = clip.duration # ê¸¸ì´ë¥¼ ì´ˆ ë‹¨ìœ„ë¡œ ë°˜í™˜
        clip.close()
        return duration
    except Exception as e:
        print(f"Error processing {file_path}: {e}")
        return None

# ffmpegë¡œ ë©”íƒ€ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¨ë‹¤ (ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì ë‹¤)
def get_video_duration(filepath):
    try:
        probe = ffmpeg.probe(filepath)
        video_info = next(s for s in probe['streams'] if s['codec_type'] == 'video')
        return float(video_info['duration'])
    except Exception as e:
        print(f"Error getting video duration: {e}")
        return None
    
def delete_short_videos():
    '''ë¹„ë””ì˜¤ íŒŒì¼ ì¶œë ¥ + args[1] ë³´ë‹¤ ì‘ìœ¼ë©´ íœ´ì§€í†µ'''
    current_time = time.time()
    min_length = 60 # 1ë¶„
    directory = work_directory

    for filename in os.listdir(directory):
        if filename.lower().endswith(video_extensions):
            file_path = os.path.join(directory, filename)
            last_modified_time = os.path.getmtime(file_path)

            if current_time - last_modified_time > 900:  # 15ë¶„
                duration = get_video_length(file_path)
                if duration is not None and duration < min_length:
                    if os.path.exists(file_path):
                        normalized_path = os.path.normpath(file_path)
                        try:
                            send2trash(normalized_path)  # íœ´ì§€í†µìœ¼ë¡œ ë³´ë‚´ê¸°
                            # print(f"Deleted [ {filename} ] as it is shorter than {min_length} seconds.")
                        except FileNotFoundError:
                            print(f"File not found: {normalized_path}. It may have been deleted already.")
                        except Exception as e:
                            print(f"Error sending {normalized_path} to trash: {e}")
                    else:
                        print(f"File does not exist: {file_path}. Skipping deletion.")


# # ìŠ¤ë ˆë“œ ì‹œì‘ (ì¸ë„¤ì¼ ìƒì„±ì´ ëŠ˜ì–´ì§„ë‹¤..?)
# # threading.Thread(target=update_task_status, daemon=True).start()
#
# # ìŠ¤ì¼€ì¤„ëŸ¬ì— ì‘ì—… ì¶”ê°€, max_instances ê¸°ë³¸ 1
# # scheduler.add_job(update_task_status, 'interval', seconds=10, max_instances=6, coalesce=True)
# # scheduler.add_job(cleanup_tasks, 'interval', minutes=1)
# # scheduler.add_job(delete_short_videos, 'interval', minutes=10)
# scheduler.add_job(compress_directory_to_zip, 'interval', minutes=60)
#
# #scheduler.start()

# CPU ë°”ìš´ë“œ ì‘ì—…: ë””ë ‰í† ë¦¬ë¥¼ ì••ì¶•í•˜ëŠ” í•¨ìˆ˜
def compress_directory_to_zip():
    for dir_to_compress in DIRECTORIES_TO_COMPRESS:

        if not os.path.exists(dir_to_compress):
            print(f"Directory does not exist: {dir_to_compress}")
            continue

        # í•˜ìœ„ ë””ë ‰í† ë¦¬ ëª©ë¡ ìˆ˜ì§‘
        subdirs = []
        for item in os.listdir(dir_to_compress):
            subdir_path = os.path.join(dir_to_compress, item)
            if os.path.isdir(subdir_path):
                subdirs.append(subdir_path)

        if subdirs:
            # í•˜ìœ„ ë””ë ‰í† ë¦¬ê°€ ìˆìœ¼ë©´ ê° í•˜ìœ„ ë””ë ‰í† ë¦¬ë¥¼ ì••ì¶•
            for subdir_path in subdirs:
                compress_directory(subdir_path)
        else:
            # í•˜ìœ„ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ í˜„ì¬ ë””ë ‰í† ë¦¬ ë‚´ì˜ íŒŒì¼ë“¤ì„ ì••ì¶•
            compress_directory(dir_to_compress)

    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S,%f")[:-3]
    print(f"### {current_time} - All Directory successfully compressed")

def compress_directory(directory):
#     print(f'compressing to {directory}')
    today_str = datetime.now().strftime("%y%m%d")
    base_name = os.path.basename(directory)
    prefix = f"compressed_{base_name}_"
    new_zip_filename = f"{prefix}{today_str}.zip"
    new_zip_filepath = os.path.join(directory, new_zip_filename)
    old_zip_filename = f"{prefix}.zip"
    old_zip_filepath = os.path.join(directory, old_zip_filename)

    # ì••ì¶• ì „ì— ì´ì „ ë‚ ì§œì˜ ì••ì¶• íŒŒì¼ ì‚­ì œ
    pattern = re.compile(rf"^{re.escape(prefix)}\d{{6}}\.zip$")

    for filename in os.listdir(directory):
        if pattern.match(filename) and filename != new_zip_filename:
            try:
                os.remove(os.path.join(directory, filename))
                print(f"ğŸ§¹ ì´ì „ ì••ì¶•íŒŒì¼ ì‚­ì œ: {filename}")
            except Exception as e:
                print(f"âš ï¸ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {filename}, {e}")

    try:
        # ZIP íŒŒì¼ ìƒì„± (ê¸°ë³¸ ZIP_STORED : ì••ì¶• x, ZIP_DEFLATED : deflate ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì••ì¶•)
        # withë¬¸ì€ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì—­í•  + ë¸”ë¡ì´ ëë‚˜ë©´ ìë™ìœ¼ë¡œ ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬ (close() í˜¸ì¶œ)
        with zipfile.ZipFile(new_zip_filepath, 'w', zipfile.ZIP_DEFLATED) as zipf:
            # os.walk()ëŠ” ë””ë ‰í„°ë¦¬ ë‚´ì˜ ëª¨ë“  íŒŒì¼ê³¼ í´ë”ë¥¼ ì¬ê·€ì ìœ¼ë¡œ íƒìƒ‰í•˜ëŠ” ë° ì‚¬ìš©í•˜ëŠ” Pythonì˜ ë‚´ì¥ í•¨ìˆ˜
            for root, dirs, files in os.walk(directory):
                for file in files:
                    # ì••ì¶• íŒŒì¼ ìì²´ëŠ” í¬í•¨í•˜ì§€ ì•ŠìŒ
                    if file == old_zip_filename or file.lower().endswith('.zip'):
                        continue
                    file_path = os.path.join(root, file)
                    arcname = os.path.relpath(file_path, directory) # fileê³¼ ëª…ì¹­ ë™ì¼
                    zipf.write(file_path, arcname)
    except Exception as e:
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S,%f")[:-3]
        print(f"### {current_time} - Error while compressing {directory}: {e}")
        return

    try:
        # ê¸°ì¡´ ì••ì¶•íŒŒì¼ì´ ìˆë‹¤ë©´ ì‚­ì œ
        # if os.path.exists(old_zip_filepath):
        #     os.remove(old_zip_filepath)
        # # ìƒˆ ì••ì¶•íŒŒì¼ì˜ ì´ë¦„ì„ ê¸°ì¡´ ì••ì¶•íŒŒì¼ëª…ìœ¼ë¡œ ë³€ê²½
        # os.rename(new_zip_filepath, old_zip_filepath)

        # ì••ì¶• ëë‚œ íŒŒì¼ì„ .zip01 ìœ¼ë¡œ ë³€ê²½
        zip01_path = old_zip_filepath + "01"
        os.rename(new_zip_filepath, zip01_path)

        # ë””ë ‰í† ë¦¬ ë‚´ì˜ ëª¨ë“  .zip íŒŒì¼ ì‚­ì œ
        for f in os.listdir(directory):
            if f.lower().endswith('.zip'):
                try:
                    os.remove(os.path.join(directory, f))
                except Exception as e:
                    print(f"ì‚­ì œ ì‹¤íŒ¨: {f} â†’ {e}")

        # .zip01 â†’ .zip ìœ¼ë¡œ ë‹¤ì‹œ ì´ë¦„ ë³€ê²½
        os.rename(zip01_path, old_zip_filepath)
    except Exception as e:
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S,%f")[:-3]
        print(f"### {current_time} - Error while renaming zip file: {e}")





# ë§¤ì‹œ ì •ê°ë§ˆë‹¤ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜
def periodic_compression_task():
    try:
        while True:
            now = datetime.now()
            next_hour = (now + timedelta(hours=1)).replace(minute=0, second=0, microsecond=0)
            sleep_duration = (next_hour - now).total_seconds()
            # sleep_duration = 60 # 1ë¶„ í…ŒìŠ¤íŠ¸
            time.sleep(sleep_duration)
            compress_directory_to_zip()
    except KeyboardInterrupt:
        print("ì••ì¶• ì‘ì—… ì¤‘ë‹¨ë¨")

def run_async_function(coroutine):
    """ ìŠ¤ì¼€ì¤„ëŸ¬ì—ì„œ ë¹„ë™ê¸° í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ëŠ” ë˜í¼ í•¨ìˆ˜ """
    loop = asyncio.get_event_loop()
    asyncio.run_coroutine_threadsafe(coroutine, loop)

async def run_schedule():
#     schedule.every().wednesday.at("10:01").do(lambda: asyncio.create_task(async_buy_lotto()))
    schedule.every().saturday.at("08:00").do(lambda: run_async_function(async_buy_lotto()))

    while True:
        schedule.run_pending()
        await asyncio.sleep(60)  # 1ë¶„ë§ˆë‹¤ ì²´í¬

def start_lotto_scheduler():
    """ë©€í‹°í”„ë¡œì„¸ì‹± í™˜ê²½ì—ì„œ ë¹„ë™ê¸° ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰"""
    # loop = asyncio.get_event_loop()
    # RuntimeError: There is no current event loop in thread ì—ëŸ¬ ë°œìƒ
    # ì¦‰, asyncioëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œë§Œ event loopë¥¼ ìë™ìœ¼ë¡œ ë§Œë“¤ì–´ì¤Œ
    # ì„œë¸Œ ìŠ¤ë ˆë“œì—ì„œëŠ” ì§ì ‘ ë§Œë“¤ì–´ì•¼ í•œë‹¤

    loop = asyncio.new_event_loop()  # ìƒˆë¡œìš´ ì´ë²¤íŠ¸ ë£¨í”„ ìƒì„±
    asyncio.set_event_loop(loop)  # ì´ë²¤íŠ¸ ë£¨í”„ ì„¤ì •
    try:
        loop.run_until_complete(run_schedule())  # ë¹„ë™ê¸° ì½”ë“œ ì‹¤í–‰
    except KeyboardInterrupt:
        print("ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œë¨")

# ì£¼ê¸°ì  ì‘ì—…ì„ ìœ„í•œ í”„ë¡œì„¸ìŠ¤ ì‹œì‘ (ë‘ ê°œì˜ ë³„ë„ í”„ë¡œì„¸ìŠ¤ë¥¼ ë°ëª¬ìœ¼ë¡œ ì‹¤í–‰, ì•±ì´ ë˜ ìƒì„±ë¨)
# asyncio ë˜ëŠ” threading.Threadë¥¼ ì‚¬ìš©í•˜ë©´, Waitress ì•± í•˜ë‚˜ ì•ˆì—ì„œ ì£¼ê¸°ì‘ì—…, ìŠ¤ì¼€ì¤„ëŸ¬ ë“±ì„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ ê°€ëŠ¥
# ì••ì¶•, ìŠ¤ì¼€ì¤„ëŸ¬, ë¡œê·¸ ì²´í¬ ê°™ì€ ì‘ì—…ì´ I/O ì¤‘ì‹¬ì´ë©´ â†’ threading ë˜ëŠ” asyncioë¡œ ì¶©ë¶„
# ì§„ì§œ ë³‘ë ¬ CPU ê³„ì‚°ì´ë¼ë©´ â†’ multiprocessing
def start_periodic_task():
    processes = []
    process = multiprocessing.Process(target=periodic_compression_task)
    process.daemon = True
    process.start()
    processes.append(process)

    process2 = multiprocessing.Process(target=start_lotto_scheduler)
    process2.daemon = True
    process2.start()
    processes.append(process2)

    return processes

def start_background_tasks():
    threading.Thread(target=periodic_compression_task, daemon=True).start()
    threading.Thread(target=start_lotto_scheduler, daemon=True).start()

def initialize_directories():
    for directory in DIRECTORIES_TO_COMPRESS:
        os.makedirs(directory, exist_ok=True)

initialize_directories()

# ìŠ¤ë ˆë“œ ì‹œì‘ (ì¸ë„¤ì¼ ìƒì„±ì´ ëŠ˜ì–´ì§„ë‹¤..?)
# threading.Thread(target=update_task_status, daemon=True).start()

# ìŠ¤ì¼€ì¤„ëŸ¬ì— ì‘ì—… ì¶”ê°€, max_instances ê¸°ë³¸ 1
# scheduler.add_job(update_task_status, 'interval', seconds=10, max_instances=6, coalesce=True)
# scheduler.add_job(cleanup_tasks, 'interval', minutes=1)
# scheduler.add_job(delete_short_videos, 'interval', minutes=10)

# scheduler.add_job(compress_directory_to_zip, 'interval', minutes=60)

# scheduler.start()

'''
threading.Thread - ê°„ë‹¨í•œ ë¹„ë™ê¸° ì‘ì—…, GIL(Global Interpreter Lock) ë¬¸ì œ - í•˜ë‚˜ì˜ ì“°ë ˆë“œë§Œ ì¸í„°í”„ë¦¬í„°ì˜ ëª¨ë“  ìì›ì„ ì‚¬ìš© > ì»¨í…ìŠ¤íŠ¸ ìŠ¤ìœ„ì¹­ ë¹„ìš©ì´ ë°œìƒ
CPU ë°”ìš´ë“œ ì‘ì—…ì—ëŠ” multiprocessing ëª¨ë“ˆì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ë” ì í•© - GILì˜ ì œì•½ì„ ë°›ì§€ ì•ŠëŠ” ë³„ë„ì˜ í”„ë¡œì„¸ìŠ¤

asyncio - ë¹„ë™ê¸° I/O ì‘ì—…ì— íš¨ìœ¨ì , ì´ë²¤íŠ¸ ë£¨í”„ ê¸°ë°˜, ìŠ¤ë ˆë“œë³´ë‹¤ ê°€ë²¼ìš´ êµ¬ì¡°

concurrent.futures.ThreadPoolExecutor - ìŠ¤ë ˆë“œ ê´€ë¦¬ë¥¼ ìë™í™”í•˜ê³ , ì‹¤í–‰ ê²°ê³¼ë¥¼ ì‰½ê²Œ ì¶”ì 

---------------------------------------------------------

multiprocessing - í”„ë¡œì„¸ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë³‘ë ¬ ì²˜ë¦¬ë¥¼ êµ¬í˜„, GIL ì˜í–¥ì´ ì—†ìŒ, ë‹¤ì¤‘ ì½”ì–´ CPU í™œìš©, í”„ë¡œì„¸ìŠ¤ ê°„ ë©”ëª¨ë¦¬ ë¶„ë¦¬, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë†’ìŒ, í”„ë¡œì„¸ìŠ¤ ìƒì„±ë¹„ìš©ì€ ìŠ¤ë ˆë“œ ìƒì„±ë¹„ìš© ë³´ë‹¤ ë†’ë‹¤

concurrent.futures.ThreadPoolExecutor - ìŠ¤ë ˆë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë³‘ë ¬ ì²˜ë¦¬, GIL ì˜í–¥ì„ ë°›ëŠ”ë‹¤, I/O ë°”ìš´ë“œ ì‘ì—…ì— ì í•©, futures ê°ì²´ë¡œ ì‘ì—…ì˜ ì™„ë£Œ ìƒíƒœë¥¼ ê´€ë¦¬, concurrent.futures APIëŠ” ì‘ì—… ì œì¶œ, ì™„ë£Œ ì¶”ì , ê²°ê³¼ ìˆ˜ì§‘ì„ ê°„ë‹¨í•˜ê²Œ ì²˜ë¦¬, ë‹¤ì¤‘ ì½”ì–´ í™œìš©ì´ ì œí•œì 
'''

'''
1. APScheduler
ì˜ˆì•½ëœ ì‘ì—…ì„ ë“±ë¡í•´ì„œ ìë™ìœ¼ë¡œ ì‹¤í–‰í•˜ëŠ” "ìŠ¤ì¼€ì¤„ëŸ¬" ë¼ì´ë¸ŒëŸ¬ë¦¬
(ì •í•´ì§„ ì‹œê°„, ì£¼ê¸°, í¬ë¡  ë“± ì§€ì›)
- ì‹¤í–‰ ë°©ì‹ : ë‚´ë¶€ì ìœ¼ë¡œ threading, asyncio, processpool ì¤‘ ì„ íƒ ê°€ëŠ¥
- ì‚¬ìš© ì˜ˆ : ì£¼ê¸°ì  DB ì •ë¦¬, ë°±ì—…, ì•ŒëŒ, ë¦¬í¬íŠ¸ ì‘ì—… ë“±

    from apscheduler.schedulers.background import BackgroundScheduler

    def job():
        print("ì‘ì—… ì‹¤í–‰!")

    scheduler = BackgroundScheduler()
    scheduler.add_job(job, 'interval', seconds=5)
    scheduler.start()
'''

'''
2. threading
ë³‘ë ¬ë¡œ ì½”ë“œë¥¼ ëŒë¦¬ê¸° ìœ„í•œ Python ë‚´ì¥ ë°©ì‹
ì‹¤ì œëŠ” ì§„ì§œ ë³‘ë ¬ì€ ì•„ë‹˜ (GIL ì˜í–¥ ë°›ìŒ)
- ì‹¤í–‰ ë°©ì‹ : OS ì“°ë ˆë“œë¥¼ ì´ìš©í•˜ë˜ GIL ê³µìœ 
- ë³‘ë ¬ì„± : âŒ CPU ë³‘ë ¬ì„± ì—†ìŒ (ë‹¨ì¼ Python ì¸í„°í”„ë¦¬í„°)
- ì í•© ì‘ì—… : I/O ìœ„ì£¼ì˜ ë°˜ë³µ ì‘ì—…, ë¡œê·¸ ìˆ˜ì§‘, í´ë§ ë“±

    import threading

    def background_task():
        while True:
            print("ë°±ê·¸ë¼ìš´ë“œ ë™ì‘")

    t = threading.Thread(target=background_task, daemon=True)
    t.start()

3. asyncio
Pythonì˜ ë¹„ë™ê¸° ì²˜ë¦¬ í”„ë ˆì„ì›Œí¬ (ì‹±ê¸€ ìŠ¤ë ˆë“œ ê¸°ë°˜)
await, async def, ì´ë²¤íŠ¸ ë£¨í”„ ê¸°ë°˜ìœ¼ë¡œ ì‘ë™
- ëª©ì  : ë¹„ë™ê¸° I/O, ê³ ì„±ëŠ¥ ì„œë²„, ë³‘ë ¬ ìš”ì²­ ì²˜ë¦¬
- ì‹¤í–‰ ë°©ì‹ : ë‹¨ì¼ ì“°ë ˆë“œ + ë…¼ë¸”ë¡œí‚¹ ë°©ì‹ (ì½”ë£¨í‹´ ìŠ¤ì¼€ì¤„ë§)
- ë³‘ë ¬ì„± : âŒ CPU ë³‘ë ¬ì€ ì•„ë‹˜ (í•˜ì§€ë§Œ I/O ë³‘ë ¬í™”ì— ë§¤ìš° íš¨ìœ¨ì )
- ì í•© ì‘ì—… : API í˜¸ì¶œ, ë¹„ë™ê¸° DB, íŒŒì¼ I/O ë“±

    import asyncio

    async def async_task():
        while True:
            print("ë¹„ë™ê¸° ì‘ì—… ì¤‘")
            await asyncio.sleep(5)

    asyncio.run(async_task())

4. concurrent.futures.ThreadPoolExecutor
ìŠ¤ë ˆë“œë¥¼ í’€ë¡œ ë¬¶ì–´ì„œ, ì‘ì—… í ê¸°ë°˜ìœ¼ë¡œ ë™ì‹œì— ì—¬ëŸ¬ ì‘ì—…ì„ ì²˜ë¦¬í•˜ê²Œ í•´ì£¼ëŠ” ê³ ìˆ˜ì¤€ ë¹„ë™ê¸° API
- ì‹¤í–‰ ë°©ì‹ : ì“°ë ˆë“œ í’€ (í ê¸°ë°˜)
- ë³‘ë ¬ì„± : ì œí•œëœ ìˆ˜ì˜ ìŠ¤ë ˆë“œë¡œ ë³‘ë ¬ ì²˜ë¦¬

    from concurrent.futures import ThreadPoolExecutor

    def task(x):
        return x * x

    with ThreadPoolExecutor(max_workers=3) as executor:
        futures = [executor.submit(task, i) for i in range(5)]
        results = [f.result() for f in futures]

- ìŠ¤ë ˆë“œ ìˆ˜ë¥¼ ì œí•œí•´ì„œ ë™ì‹œì— ì‹¤í–‰
    with ThreadPoolExecutor(max_workers=5) as executor:
        executor.submit(task1)
        executor.submit(task2)

- Future ê°ì²´ë¡œ ê²°ê³¼/ì˜ˆì™¸ë¥¼ ë‹¤ë£° ìˆ˜ ìˆìŒ
    future = executor.submit(task)
    try:
        result = future.result(timeout=5)
    except Exception as e:
        print(f"ì—ëŸ¬ ë°œìƒ: {e}")
'''